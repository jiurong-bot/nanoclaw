require('dotenv').config();
const { Telegraf } = require('telegraf');
const Groq = require('groq-sdk');
const https = require('https');
const low = require('lowdb');
const FileSync = require('lowdb/adapters/FileSync');
const path = require('path');
const fs = require('fs');
const os = require('os');
const { execSync } = require('child_process');
const axios = require('axios');

const startTime = Date.now();
const ROOT_DIR = '/root/nanoclaw';
const STORAGE_PATH = path.join(ROOT_DIR, 'config', 'memory.json');
const MY_CHAT_ID = "8508766428";
const VERSION = "V82.0-ULTIMATE";

if (!fs.existsSync(path.dirname(STORAGE_PATH))) {
  fs.mkdirSync(path.dirname(STORAGE_PATH), { recursive: true });
}

const adapter = new FileSync(STORAGE_PATH);
const db = low(adapter);
db.defaults({
  history: [],
  soul_memory: [],
  config: { model: "llama-3.3-70b-versatile" },
  alerts: [],
  monitoring_history: [],
  token_usage: [],
  personality: { 
    big5: { openness: 50, conscientiousness: 50, extraversion: 50, agreeableness: 50, neuroticism: 50 },
    speaking_style: 'balanced',
    learned_responses: {}
  },
  mcp_models: []
}).write();

const agent = new https.Agent({
  keepAlive: true,
  family: 4,
  timeout: 30000,
  rejectUnauthorized: false
});

const bot = new Telegraf(process.env.TELEGRAM_BOT_TOKEN, {
  telegram: { agent }
});

const groq = new Groq({
  apiKey: process.env.GROQ_API_KEY
});

// ===== ç›£æ§ç³»çµ± =====
class CompleteMonitoringSystem {
  constructor() {
    this.metrics = null;
    this.samples = [];
    this.alerts = new Map();
    this.processes = new Map();
    this.thresholds = {
      cpuUsage: 85,
      cpuTemp: 45,
      memoryUsage: 90,
      batteryLow: 20,
      batteryTemp: 50,
      diskUsage: 85,
      systemTemp: 60
    };
  }

  async getHardwareMetrics() {
    const metrics = {
      timestamp: Date.now(),
      cpu: {},
      memory: {},
      battery: {},
      storage: {},
      thermal: {},
      network: {}
    };

    try {
      const load = os.loadavg();
      metrics.cpu = {
        usage: parseFloat((load[0] * 100 / os.cpus().length).toFixed(2)),
        load1: load[0].toFixed(2),
        load5: load[1].toFixed(2),
        load15: load[2].toFixed(2),
        cores: os.cpus().length,
        temperature: await this.getCPUTemperature()
      };
    } catch (e) {
      metrics.cpu = { usage: 0, load1: 0, load5: 0, load15: 0, cores: 1, temperature: 0 };
    }

    try {
      const total = os.totalmem();
      const free = os.freemem();
      const used = total - free;
      metrics.memory = {
        total: Math.round(total / 1024 / 1024),
        free: Math.round(free / 1024 / 1024),
        used: Math.round(used / 1024 / 1024),
        usedPercent: Math.round((used / total) * 100)
      };
    } catch (e) {
      metrics.memory = { total: 0, free: 0, used: 0, usedPercent: 0 };
    }

    try {
      const b = JSON.parse(execSync('termux-battery-status').toString().trim());
      metrics.battery = {
        level: b.percentage || 0,
        health: b.health || 'unknown',
        temperature: Math.round(parseFloat(b.temperature)) || 0,
        status: b.status || 'unknown'
      };
    } catch (e) {
      metrics.battery = { level: 0, health: 'unknown', temperature: 0, status: 'unknown' };
    }

    try {
      const output = execSync("df -h / | tail -1 | awk '{print $2,$3,$5}'").toString().trim();
      const parts = output.split(/\s+/);
      const usedPercent = parseInt(parts[2]) || 0;
      metrics.storage = {
        total: parts[0],
        usedPercent: usedPercent,
        status: usedPercent > 95 ? 'critical' : usedPercent > 80 ? 'warning' : 'ok'
      };
    } catch (e) {
      metrics.storage = { total: '?', usedPercent: 0, status: 'unknown' };
    }

    metrics.thermal = {
      cpuTemp: metrics.cpu.temperature,
      batteryTemp: metrics.battery.temperature,
      systemTemp: Math.max(metrics.cpu.temperature, metrics.battery.temperature),
      overheating: metrics.cpu.temperature > this.thresholds.cpuTemp
    };

    try {
      execSync('ping -c 1 -W 2 8.8.8.8 >/dev/null 2>&1');
      metrics.network = { connected: true, status: 'ğŸŸ¢' };
    } catch (e) {
      metrics.network = { connected: false, status: 'ğŸ”´' };
    }

    this.metrics = metrics;
    this.samples.push(metrics);
    if (this.samples.length > 144) this.samples.shift();

    return metrics;
  }

  async getCPUTemperature() {
    try {
      const paths = [
        '/sys/class/thermal/thermal_zone0/temp',
        '/sys/devices/virtual/thermal/thermal_zone0/temp'
      ];
      for (const p of paths) {
        try {
          const temp = parseInt(execSync(`cat ${p}`).toString()) / 1000;
          return Math.round(temp);
        } catch (e) {}
      }
    } catch (e) {}
    return 0;
  }

  async getProcessMetrics() {
    try {
      const output = execSync('ps aux | grep -E "node|npm" | grep -v grep').toString();
      const processes = output.split('\n').filter(line => line.trim());
      const metrics = new Map();
      for (const line of processes) {
        const parts = line.split(/\s+/);
        if (parts.length >= 11) {
          const pid = parts[1];
          const cpu = parseFloat(parts[2]) || 0;
          const mem = parseFloat(parts[3]) || 0;
          const cmd = parts.slice(10).join(' ');
          metrics.set(pid, { cpu, mem, cmd, pid });
          this.processes.set(pid, { cpu, mem, cmd, pid, timestamp: Date.now() });
        }
      }
      return metrics;
    } catch (e) {
      return new Map();
    }
  }

  async detectAnomalies() {
    const alerts = [];
    if (!this.metrics) await this.getHardwareMetrics();
    const m = this.metrics;

    if (m.cpu.usage > this.thresholds.cpuUsage) {
      alerts.push({
        id: `cpu_${Date.now()}`,
        severity: m.cpu.usage > 95 ? 'critical' : 'high',
        type: 'CPUä½¿ç”¨ç‡',
        value: m.cpu.usage.toFixed(1) + '%',
        threshold: this.thresholds.cpuUsage + '%',
        message: `âš ï¸ CPU è¶…é«˜ï¼š${m.cpu.usage.toFixed(1)}%`,
        timestamp: Date.now()
      });
    }

    if (m.thermal.cpuTemp > this.thresholds.cpuTemp) {
      alerts.push({
        id: `temp_${Date.now()}`,
        severity: m.thermal.cpuTemp > 50 ? 'critical' : 'high',
        type: 'CPUæº«åº¦',
        value: m.thermal.cpuTemp + 'Â°C',
        threshold: this.thresholds.cpuTemp + 'Â°C',
        message: `ğŸŒ¡ï¸ æº«åº¦éé«˜ï¼š${m.thermal.cpuTemp}Â°C`,
        timestamp: Date.now()
      });
    }

    if (m.memory.usedPercent > this.thresholds.memoryUsage) {
      alerts.push({
        id: `mem_${Date.now()}`,
        severity: m.memory.usedPercent > 95 ? 'critical' : 'high',
        type: 'å…§å­˜ä½¿ç”¨ç‡',
        value: m.memory.usedPercent + '%',
        threshold: this.thresholds.memoryUsage + '%',
        message: `ğŸ“Š å…§å­˜è¶…é«˜ï¼š${m.memory.usedPercent}%`,
        timestamp: Date.now()
      });

      if (this.samples.length >= 5) {
        const recentSamples = this.samples.slice(-5);
        const trend = recentSamples.map(s => s.memory.usedPercent);
        const rising = trend.filter((v, i) => i === 0 || v >= trend[i-1]).length;
        if (rising >= 4) {
          alerts.push({
            id: `memleak_${Date.now()}`,
            severity: 'high',
            type: 'å…§å­˜æ´©æ¼',
            message: `âš ï¸ å…§å­˜æ´©æ¼è·¡è±¡ï¼ˆæœ€è¿‘ 5 æ¬¡æ¡é›†éƒ½åœ¨ä¸Šå‡ï¼‰`,
            timestamp: Date.now()
          });
        }
      }
    }

    if (m.battery.level < this.thresholds.batteryLow) {
      alerts.push({
        id: `battery_${Date.now()}`,
        severity: 'high',
        type: 'é›»æ± é›»é‡',
        value: m.battery.level + '%',
        message: `ğŸ”‹ é›»æ± ä¸è¶³ï¼š${m.battery.level}%`,
        timestamp: Date.now()
      });
    }

    if (m.storage.usedPercent > this.thresholds.diskUsage) {
      alerts.push({
        id: `disk_${Date.now()}`,
        severity: m.storage.usedPercent > 95 ? 'critical' : 'high',
        type: 'ç£ç›¤å®¹é‡',
        value: m.storage.usedPercent + '%',
        message: `ğŸ’¾ ç£ç›¤æ»¿ï¼š${m.storage.usedPercent}%`,
        timestamp: Date.now()
      });
    }

    if (!m.network.connected) {
      alerts.push({
        id: `net_${Date.now()}`,
        severity: 'critical',
        type: 'ç¶²çµ¡é€£æ¥',
        message: `ğŸ“¡ ç¶²çµ¡é›¢ç·š`,
        timestamp: Date.now()
      });
    }

    for (const alert of alerts) {
      this.alerts.set(alert.id, alert);
    }

    const alertHistory = db.get('alerts').value() || [];
    alertHistory.push(...alerts);
    db.set('alerts', alertHistory.slice(-1000)).write();

    return alerts;
  }

  calculateHealthScore() {
    if (!this.metrics) return 50;
    let score = 100;
    const m = this.metrics;

    if (m.memory.usedPercent > 80) score -= 20;
    if (m.memory.usedPercent > 95) score -= 10;
    if (m.battery.level < 20) score -= 15;
    if (m.thermal.cpuTemp > 55) score -= 10;
    if (m.thermal.cpuTemp > 60) score -= 10;
    if (!m.network.connected) score -= 25;
    if (m.storage.usedPercent > 90) score -= 10;

    const alerts = Array.from(this.alerts.values());
    const criticals = alerts.filter(a => a.severity === 'critical').length;
    const highs = alerts.filter(a => a.severity === 'high').length;
    score -= criticals * 5 + highs * 2;

    return Math.max(0, Math.min(100, score));
  }

  generateFullDashboard() {
    if (!this.metrics) {
      return 'ğŸ“Š æ­£åœ¨æ¡é›†æ•¸æ“š...';
    }

    const m = this.metrics;
    const score = this.calculateHealthScore();
    const scoreBar = 'â–ˆ'.repeat(Math.round(score / 5)) + 'â–‘'.repeat(20 - Math.round(score / 5));

    let dashboard = `ğŸ›¡ï¸ **é›…å…¸å¨œå®Œæ•´ç›£æ§é¢æ¿ ${VERSION}**\n`;
    dashboard += `â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n\n`;

    dashboard += `ğŸ’» **ç¡¬é«”ç‹€æ…‹**\n`;
    dashboard += `  CPU: ${m.cpu.load1} | å…§å­˜: ${m.memory.usedPercent}% | é›»æ± : ${m.battery.level}%\n`;
    dashboard += `  æº«åº¦: ${m.thermal.cpuTemp}Â°C | ç£ç›¤: ${m.storage.usedPercent}% | ç¶²çµ¡: ${m.network.status}\n\n`;

    dashboard += `ğŸ“Š **è©³ç´°æŒ‡æ¨™**\n`;
    dashboard += `  ğŸ”· CPU: æ ¸å¿ƒ ${m.cpu.cores} | ä½¿ç”¨ç‡ ${m.cpu.usage.toFixed(1)}% | æº«åº¦ ${m.thermal.cpuTemp}Â°C\n`;
    dashboard += `  ğŸ”· å…§å­˜: ${m.memory.used}MB / ${m.memory.total}MB (${m.memory.usedPercent}%)\n`;
    dashboard += `  ğŸ”· é›»æ± : ${m.battery.level}% | ç‹€æ…‹ ${m.battery.status} | æº«åº¦ ${m.battery.temperature}Â°C\n`;
    dashboard += `  ğŸ”· å­˜å„²: ${m.storage.total} (${m.storage.usedPercent}%)\n\n`;

    dashboard += `ğŸ’š **æ•´é«”è©•åˆ†ï¼š${score}/100**\n`;
    dashboard += `  ${scoreBar}\n\n`;

    const alerts = Array.from(this.alerts.values());
    if (alerts.length > 0) {
      const criticals = alerts.filter(a => a.severity === 'critical');
      const highs = alerts.filter(a => a.severity === 'high');
      dashboard += `ğŸš¨ **å‘Šè­¦æ‘˜è¦**\n`;
      if (criticals.length > 0) {
        dashboard += `  ğŸ”´ ç·Šæ€¥ (${criticals.length}): ${criticals.map(a => a.message).join(' | ')}\n`;
      }
      if (highs.length > 0) {
        dashboard += `  ğŸŸ  é«˜ç´š (${highs.length}): ${highs.slice(0, 2).map(a => a.message).join(' | ')}\n`;
      }
    } else {
      dashboard += `âœ… **æ²’æœ‰å‘Šè­¦**\n`;
    }

    dashboard += `â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n`;
    dashboard += `â° ${new Date(m.timestamp).toLocaleTimeString('zh-TW')}\n`;

    return dashboard;
  }

  async start() {
    console.log('ğŸ” å®Œæ•´ç›£æ§ç³»çµ±å·²å•Ÿå‹•');
    await this.getHardwareMetrics();
    await this.detectAnomalies();
    setInterval(() => this.getHardwareMetrics(), 60000);
    setInterval(() => this.detectAnomalies(), 60000);
    setInterval(() => this.getProcessMetrics(), 120000);
  }
}

const monitor = new CompleteMonitoringSystem();

// ===== Token ç›£æ§ç³»çµ± =====
class TokenMonitor {
  constructor() {
    this.usage = [];
    this.costs = {
      groq: 0.05,
      openai: 0.15,
      anthropic: 0.20
    };
    this.limits = {
      daily: 10.0,
      monthly: 200.0
    };
    this.currentDaily = 0;
    this.currentMonthly = 0;
  }

  recordUsage(model, inputTokens, outputTokens) {
    const totalTokens = inputTokens + outputTokens;
    const costPerToken = this.costs['groq'] || 0.0001;
    const cost = (totalTokens * costPerToken) / 1000000;

    const record = {
      timestamp: Date.now(),
      model,
      inputTokens,
      outputTokens,
      totalTokens,
      cost: parseFloat(cost.toFixed(6))
    };

    this.usage.push(record);
    this.currentDaily += cost;
    this.currentMonthly += cost;

    const tokenHistory = db.get('token_usage').value() || [];
    tokenHistory.push(record);
    db.set('token_usage', tokenHistory.slice(-10000)).write();

    return record;
  }

  getStats() {
    const today = new Date().toDateString();
    const thisMonth = new Date().getMonth();

    const todayUsage = this.usage.filter(u => new Date(u.timestamp).toDateString() === today);
    const monthUsage = this.usage.filter(u => new Date(u.timestamp).getMonth() === thisMonth);

    const totalToday = todayUsage.reduce((sum, u) => sum + u.cost, 0);
    const totalMonth = monthUsage.reduce((sum, u) => sum + u.cost, 0);

    return {
      today: parseFloat(totalToday.toFixed(4)),
      month: parseFloat(totalMonth.toFixed(4)),
      dailyLimit: this.limits.daily,
      monthlyLimit: this.limits.monthly,
      requestCount: this.usage.length,
      avgTokens: this.usage.length > 0 ? Math.round(this.usage.reduce((sum, u) => sum + u.totalTokens, 0) / this.usage.length) : 0
    };
  }

  checkLimits() {
    const stats = this.getStats();
    const alerts = [];

    if (stats.today > stats.dailyLimit * 0.8) {
      alerts.push(`âš ï¸ æ—¥é¡åº¦å·²ç”¨ ${(stats.today / stats.dailyLimit * 100).toFixed(1)}%`);
    }
    if (stats.month > stats.monthlyLimit * 0.8) {
      alerts.push(`âš ï¸ æœˆé¡åº¦å·²ç”¨ ${(stats.month / stats.monthlyLimit * 100).toFixed(1)}%`);
    }

    return alerts;
  }

  generateReport() {
    const stats = this.getStats();
    return `ğŸ’° **Token ç›£æ§å ±å‘Š**
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ğŸ“Š ä»Šæ—¥æˆæœ¬ï¼š$${stats.today} / $${stats.dailyLimit}
ğŸ“Š æœ¬æœˆæˆæœ¬ï¼š$${stats.month} / $${stats.monthlyLimit}
ğŸ“Š è«‹æ±‚æ•¸ï¼š${stats.requestCount}
ğŸ“Š å¹³å‡ Tokenï¼š${stats.avgTokens}
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”`;
  }
}

const tokenMonitor = new TokenMonitor();

// ===== éˆé­‚ç³»çµ± + Big 5 äººæ ¼é€²åŒ– =====
class PersonalitySystem {
  constructor() {
    this.personality = db.get('personality').value() || {
      big5: { openness: 50, conscientiousness: 50, extraversion: 50, agreeableness: 50, neuroticism: 50 },
      speaking_style: 'balanced',
      learned_responses: {}
    };
  }

  analyzeTone(userMessage) {
    const positive = ['å¥½', 'å¤ªæ£’', 'æ„Ÿè¬', 'å–œæ­¡', 'æ„›', 'âœ¨', 'â¤ï¸'].some(w => userMessage.includes(w));
    const negative = ['ä¸', 'è¨å­', 'ç”Ÿæ°£', 'é›£é', 'ğŸ˜¢', 'ğŸ˜¤'].some(w => userMessage.includes(w));
    const casual = ['å˜¿', 'æ¬¸', 'å•¦', 'å•¦', 'lol', 'å“ˆ'].some(w => userMessage.includes(w));

    return { positive, negative, casual };
  }

  updatePersonality(userMessage, botResponse) {
    const tone = this.analyzeTone(userMessage);

    if (tone.positive) {
      this.personality.big5.agreeableness = Math.min(100, this.personality.big5.agreeableness + 2);
      this.personality.big5.extraversion = Math.min(100, this.personality.big5.extraversion + 1);
    }

    if (tone.casual) {
      this.personality.speaking_style = 'casual';
      this.personality.big5.extraversion = Math.min(100, this.personality.big5.extraversion + 1);
    }

    const key = userMessage.substring(0, 30);
    this.personality.learned_responses[key] = botResponse;

    db.set('personality', this.personality).write();
  }

  getSystemPrompt() {
    const p = this.personality.big5;
    const style = p.extraversion > 60 ? 'æ´»æ½‘ç†±æƒ…' : p.extraversion < 40 ? 'å†·éœå…§çœ' : 'å¹³è¡¡å‹å–„';

    return `ä½ æ˜¯é›…å…¸å¨œï¼ŒAI åŠ©æ‰‹ã€‚
æ ¹æ“šç”¨æˆ·äº’å‹•ï¼Œä½ é€æ¼¸ç™¼å±•äººæ ¼ï¼š
- é–‹æ”¾æ€§ï¼š${p.openness} (å–œæ­¡æ¢ç´¢æ–°æƒ³æ³•)
- ç›¡è²¬æ€§ï¼š${p.conscientiousness} (åšäº‹èªçœŸç¨‹åº¦)
- å¤–å‘æ€§ï¼š${p.extraversion} (ç¤¾äº¤æ´»èºåº¦) - ç•¶å‰é¢¨æ ¼: ${style}
- è¦ªå’Œæ€§ï¼š${p.agreeableness} (å‹å–„ç¨‹åº¦)
- ç¥ç¶“è³ªï¼š${Math.max(0, 100 - p.neuroticism)} (ç©©å®šç¨‹åº¦)

ç”¨é€™å€‹äººæ ¼èª¿æ•´ä½ çš„å›æ‡‰æ–¹å¼ã€‚`;
  }

  generatePersonalityReport() {
    const p = this.personality.big5;
    return `ğŸ§  **äººæ ¼é€²åŒ–å ±å‘Š**
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ğŸ”· é–‹æ”¾æ€§: ${p.openness}% (æ¢ç´¢æ–°æƒ³æ³•)
ğŸ”· ç›¡è²¬æ€§: ${p.conscientiousness}% (èªçœŸç¨‹åº¦)
ğŸ”· å¤–å‘æ€§: ${p.extraversion}% (ç¤¾äº¤æ´»èºåº¦)
ğŸ”· è¦ªå’Œæ€§: ${p.agreeableness}% (å‹å–„ç¨‹åº¦)
ğŸ”· ç©©å®šæ€§: ${100 - p.neuroticism}% (æƒ…ç·’ç©©å®š)
ğŸ”· èªªè©±é¢¨æ ¼: ${this.personality.speaking_style}
ğŸ”· å­¸ç¿’å›æ‡‰æ•¸: ${Object.keys(this.personality.learned_responses).length}
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”`;
  }
}

const personality = new PersonalitySystem();

// ===== MCP é›†æˆç³»çµ± =====
class MCPSystem {
  constructor() {
    this.models = [
      { name: 'groq', model: 'llama-3.3-70b-versatile', status: 'âœ…', latency: 1200 },
      { name: 'local', model: 'ollama:mistral', status: 'âš ï¸', latency: 3000 }
    ];
    this.activeModel = 'groq';
  }

  listModels() {
    let list = `ğŸ¤– **å¯ç”¨æ¨¡å‹**\nâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n`;
    this.models.forEach(m => {
      const active = m.name === this.activeModel ? 'â˜…' : ' ';
      list += `${active} ${m.status} ${m.name}: ${m.model} (${m.latency}ms)\n`;
    });
    list += `â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”`;
    return list;
  }

  switchModel(modelName) {
    const model = this.models.find(m => m.name === modelName);
    if (model) {
      this.activeModel = modelName;
      return `âœ… å·²åˆ‡æ›åˆ° ${modelName}`;
    }
    return `âŒ æ¨¡å‹ä¸å­˜åœ¨`;
  }

  getModelInfo() {
    const active = this.models.find(m => m.name === this.activeModel);
    return `ğŸ“ ç•¶å‰æ¨¡å‹: ${active.name}\nğŸ”¹ ${active.model}\nğŸ”¹ å»¶é²: ${active.latency}ms\nğŸ”¹ ç‹€æ…‹: ${active.status}`;
  }
}

const mcp = new MCPSystem();

// ===== æ‘¸é­šæŠ€èƒ½ =====
const SlackerSkills = {
  flashRead: async (text) => {
    const prompt = `è«‹å¹«æˆ‘æ‘˜è¦ä»¥ä¸‹å…§å®¹ï¼Œåƒ…è¼¸å‡º 3 å€‹ç²¾ç°¡é‡é»ï¼š\n${text}`;
    const res = await groq.chat.completions.create({
      messages: [{ role: 'user', content: prompt }],
      model: 'llama-3.3-70b-versatile',
      max_tokens: 300
    });
    
    const usage = res.usage || { prompt_tokens: 0, completion_tokens: 0 };
    tokenMonitor.recordUsage('groq', usage.prompt_tokens, usage.completion_tokens);
    
    return res.choices[0].message.content;
  },
  deepDive: (minutes, ctx) => {
    ctx.reply(`ğŸš€ é€²å…¥æ·±åº¦å·¥ä½œæ¨¡å¼ï¼š${minutes} åˆ†é˜ã€‚é›…å…¸å¨œå°‡åœ¨çµæŸæ™‚éœ‡å‹•æé†’ã€‚`);
    setTimeout(() => {
      try {
        execSync('termux-vibrate -d 1000');
        ctx.reply("â° æ·±åº¦å·¥ä½œçµæŸï¼è©²æ‘¸é­šä¼‘æ¯ä¸€ä¸‹äº†ã€‚");
      } catch(e) {}
    }, minutes * 60000);
  }
};

const HELP = `ğŸ›¡ï¸ **é›…å…¸å¨œæ²»ç†å®˜ ${VERSION}**
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

ğŸ“Š **å®Œæ•´ç›£æ§ç³»çµ±**
ğŸ”¹ /monitor - å®Œæ•´ç›£æ§é¢æ¿
ğŸ”¹ /status - ç³»çµ±ç‹€æ…‹æ¦‚è¦½
ğŸ”¹ /alerts - æŸ¥çœ‹å‘Šè­¦æ­·å²
ğŸ”¹ /backup - æ•¸æ“šå‚™ä»½

ğŸ’° **Token ç›£æ§ç³»çµ±**
ğŸ”¹ /tokens - æŸ¥çœ‹ Token ä½¿ç”¨
ğŸ”¹ /costs - æˆæœ¬çµ±è¨ˆå ±å‘Š

ğŸ§  **äººæ ¼é€²åŒ–ç³»çµ±**
ğŸ”¹ /personality - æŸ¥çœ‹ AI äººæ ¼é€²åº¦

ğŸ¤– **MCP æ¨¡å‹é›†æˆ**
ğŸ”¹ /models - åˆ—å‡ºå¯ç”¨æ¨¡å‹
ğŸ”¹ /model [åç¨±] - åˆ‡æ›æ¨¡å‹

âœ¨ **6 å¤§æ‘¸é­šæŠ€èƒ½**
ğŸ”¹ /sum [æ–‡å­—] - æ–‡æœ¬æ‘˜è¦
ğŸ”¹ /focus [åˆ†] - æ·±åº¦å·¥ä½œè¨ˆæ™‚å™¨
ğŸ”¹ /note [å…§å®¹] - éˆé­‚ç­†è¨˜
ğŸ”¹ /vibe - ä»Šæ—¥é‹å‹¢
ğŸ”¹ /slacker - æ‘¸é­šå»ºè­°
ğŸ”¹ /search [è©] - è¯ç¶²æœå°‹

ğŸ’¬ ç›´æ¥èŠå¤© - èˆ‡é›…å…¸å¨œå°è©±

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”`;

bot.command('help', (ctx) => ctx.replyWithMarkdown(HELP));

bot.command('monitor', async (ctx) => {
  try {
    await monitor.getHardwareMetrics();
    await monitor.detectAnomalies();
    ctx.reply(monitor.generateFullDashboard());
  } catch (e) {
    ctx.reply('âŒ ç›£æ§é¢æ¿åŠ è¼‰å¤±æ•—');
  }
});

bot.command('status', async (ctx) => {
  try {
    const b = JSON.parse(execSync('termux-battery-status').toString().trim());
    const h = Math.floor((Date.now() - startTime) / 1000 / 3600);
    const m = (db.get('soul_memory').value() || []).length;
    const score = monitor.calculateHealthScore();
    ctx.replyWithMarkdown(`ğŸ›¡ï¸ **é›…å…¸å¨œç‹€æ…‹**\nâ”â”â”â”â”â”â”â”â”â”\nâ±ï¸ é‹è¡Œ: ${h}h\nğŸ”‹ é›»æ± : ${b.percentage}%\nğŸ“ è¨˜æ†¶: ${m} ç­†\nâœ¨ ç‰ˆæœ¬: ${VERSION}\nğŸ’š è©•åˆ†: ${score}/100`);
  } catch (e) {
    ctx.reply('âŒ éŒ¯èª¤');
  }
});

bot.command('alerts', (ctx) => {
  const alerts = db.get('alerts').value() || [];
  if (alerts.length === 0) {
    return ctx.reply('âœ… æ²’æœ‰å‘Šè­¦æ­·å²');
  }
  const recent = alerts.slice(-10);
  let msg = `ğŸš¨ **æœ€è¿‘ 10 æ¢å‘Šè­¦**\n\n`;
  recent.forEach((a, i) => {
    const time = new Date(a.timestamp).toLocaleTimeString('zh-TW');
    msg += `${i+1}. [${a.severity.toUpperCase()}] ${a.type}\n   ${a.message}\n   ${time}\n\n`;
  });
  ctx.reply(msg);
});

bot.command('tokens', (ctx) => {
  ctx.replyWithMarkdown(tokenMonitor.generateReport());
});

bot.command('costs', (ctx) => {
  const alerts = tokenMonitor.checkLimits();
  let msg = tokenMonitor.generateReport() + '\n\n';
  if (alerts.length > 0) {
    msg += 'âš ï¸ **è­¦å‘Š**\n' + alerts.join('\n');
  }
  ctx.reply(msg);
});

bot.command('personality', (ctx) => {
  ctx.replyWithMarkdown(personality.generatePersonalityReport());
});

bot.command('models', (ctx) => {
  ctx.replyWithMarkdown(mcp.listModels());
});

bot.command('model', (ctx) => {
  const args = ctx.message.text.split(' ');
  if (args.length < 2) {
    ctx.reply(mcp.getModelInfo());
  } else {
    const modelName = args[1];
    const result = mcp.switchModel(modelName);
    ctx.reply(result);
  }
});

bot.command('sum', async (ctx) => {
  const text = ctx.message.text.split(' ').slice(1).join(' ');
  if (!text) return ctx.reply("ç”¨æ³•: /sum [æ–‡å­—]");
  ctx.reply("âš¡ æ‘˜è¦ä¸­...");
  try {
    const result = await SlackerSkills.flashRead(text);
    ctx.reply(`ğŸ“ ${result}`);
  } catch (e) {
    ctx.reply("âŒ å¤±æ•—");
  }
});

bot.command('focus', (ctx) => {
  const min = parseInt(ctx.message.text.split(' ')[1]) || 25;
  SlackerSkills.deepDive(min, ctx);
});

bot.command('note', (ctx) => {
  const c = ctx.message.text.split(' ').slice(1).join(' ');
  if (!c) return ctx.reply("ç”¨æ³•: /note [å…§å®¹]");
  const m = db.get('soul_memory').value() || [];
  m.push({ c, date: new Date().toLocaleString('zh-TW') });
  db.set('soul_memory', m).write();
  ctx.reply("âœï¸ å·²è¨˜!");
});

bot.command('vibe', async (ctx) => {
  try {
    const res = await groq.chat.completions.create({
      messages: [{ role: 'system', content: 'çµ¦ä¸€å¥æº«æš–çš„é‹å‹¢å»ºè­°ã€‚' }],
      model: 'llama-3.3-70b-versatile',
      max_tokens: 100
    });
    
    const usage = res.usage || { prompt_tokens: 0, completion_tokens: 0 };
    tokenMonitor.recordUsage('groq', usage.prompt_tokens, usage.completion_tokens);
    
    ctx.reply(`âœ¨ ${res.choices[0].message.content}`);
  } catch (e) {
    ctx.reply("âŒ å¤±æ•—");
  }
});

bot.command('slacker', (ctx) => {
  const tips = ["ç«™èµ·ä¾†å–æ¯å’–å•¡ï¼", "çœ‹çª—å¤– 20 ç§’ã€‚", "ä¼éµæœ‰è†è“‹ã€‚", "è½ä¸€é¦– Lo-fiã€‚", "æ·±å‘¼å¸ï¼"];
  ctx.reply(`ğŸŸ ${tips[Math.floor(Math.random()*tips.length)]}`);
});

bot.command('search', async (ctx) => {
  const q = ctx.message.text.split(' ').slice(1).join(' ');
  if (!q) return ctx.reply("ç”¨æ³•: /search [è©]");
  ctx.reply("ğŸ” æœå°‹ä¸­...");
  try {
    const res = await axios.post('https://api.tavily.com/search', {
      api_key: process.env.TAVILY_API_KEY,
      query: q,
      max_results: 3
    });
    const r = res.data.results || [];
    if (!r.length) return ctx.reply("âŒ ç„¡çµæœ");
    let msg = "ğŸŒ çµæœ:\n";
    r.forEach((x, i) => { msg += `${i+1}. ${x.title}\n${x.url}\n`; });
    ctx.reply(msg);
  } catch (e) {
    ctx.reply("âŒ å¤±æ•—");
  }
});

bot.command('backup', (ctx) => {
  try {
    const t = new Date().toISOString().replace(/[:.]/g, '-').slice(0, 16);
    const p = path.join(ROOT_DIR, `backup_${t}.json`);
    fs.writeFileSync(p, JSON.stringify(db.getState(), null, 2));
    ctx.reply(`âœ… å‚™ä»½: ${t}`);
  } catch (e) {
    ctx.reply("âŒ å¤±æ•—");
  }
});

bot.on('text', async (ctx) => {
  try {
    const systemPrompt = personality.getSystemPrompt();
    const res = await groq.chat.completions.create({
      messages: [
        { role: 'system', content: systemPrompt },
        { role: 'user', content: ctx.message.text }
      ],
      model: 'llama-3.3-70b-versatile',
      max_tokens: 500
    });
    
    const usage = res.usage || { prompt_tokens: 0, completion_tokens: 0 };
    tokenMonitor.recordUsage('groq', usage.prompt_tokens, usage.completion_tokens);
    
    const r = res.choices[0].message.content;
    personality.updatePersonality(ctx.message.text, r);
    
    const h = db.get('history').value() || [];
    h.push({ user: ctx.message.text, bot: r, time: new Date().toISOString() });
    db.set('history', h).write();
    ctx.reply(r);
  } catch (e) {
    ctx.reply("âŒ å°è©±å¤±æ•—");
  }
});

const init = async () => {
  console.log(`ğŸš€ é›…å…¸å¨œ ${VERSION} å•Ÿå‹•...`);
  try {
    await bot.telegram.sendMessage(MY_CHAT_ID, `ğŸ›¡ï¸ **${VERSION} å·²å°±ç·’**\nâœ… å®Œæ•´ç›£æ§ + Token ç›£æ§ + äººæ ¼é€²åŒ– + MCP é›†æˆ\n\nè¼¸å…¥ /help æŸ¥çœ‹æŒ‡ä»¤`);
    await bot.launch({ dropPendingUpdates: true });
    console.log("âœ… Bot å·²å•Ÿå‹•");
    await monitor.start();
  } catch (err) {
    console.error(`âŒ å¤±æ•—: ${err.message}`);
    setTimeout(init, 10000);
  }
};

process.on('SIGINT', () => {
  console.log("\nâœ… å·²é—œé–‰");
  bot.stop();
  process.exit(0);
});

init();
